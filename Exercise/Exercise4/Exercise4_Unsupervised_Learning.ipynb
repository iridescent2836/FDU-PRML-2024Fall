{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fudan PRML Fall 2024 Exercise 4: Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![news](./news.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Your name and Student ID:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this assignment, you will build a **text classification** system which is a fundamental task in the field of Natural Language Processing (NLP). More precisely, you are given a news classification task, assigning given news texts to the categories to which they belong. Unlike traditional classification tasks, **we did not provide you with any labels for this assignment, and you need to find a way to construct labels for these articles**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For this assignment you can use commonly used deep learning frameworks like PyTorch. **You can use pretrained word vectors like Glove, but not pretrained large models like BERT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES = 1\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_path = 'kmeans_news.pkl'\n",
    "\n",
    "all_data = None\n",
    "with open(dataset_path,'rb') as fin:\n",
    "    all_data = pickle.load(fin)\n",
    "    all_data_np = np.array(all_data)\n",
    "\n",
    "print ('\\n'.join(all_data[0:5]))\n",
    "print ('Total number of news: {}'.format(len(all_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Exploratory Data Analysis\n",
    "\n",
    "Not all data within the dataset is suitable for clustering. You might need to filter and process some of them in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get embeddings for the news\n",
    "\n",
    "We need to convert the news titles into some kind of numerical representation (embedding) before we can do clustering on them. Below are two ways to get embeddings for a paragraph of text:\n",
    "\n",
    "1. **Pretrained word embeddings**: You can use pretrained word embeddings like Glove to get embeddings for each word in the news, and then average them (or try some more advanced techniques) to get the news embedding.\n",
    "\n",
    "2. **General text embedding models**: You can use general text embedding models to get embedding for a sentence directly.\n",
    "\n",
    "You can choose either of them to convert the news titles into embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 15\n",
    "kmeans = KMeans(n_clusters=clusters, random_state=0).fit(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View samples in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = True\n",
    "for i in range(clusters):\n",
    "    print(f'Cluster {i} has {np.sum(kmeans.labels_ == i)} sentences')\n",
    "    if random_sample:\n",
    "        print('\\n'.join(all_data_np[np.random.choice(np.where(kmeans.labels_ == i)[0], 5)]))\n",
    "    else:\n",
    "        print('\\n'.join(all_data_np[kmeans.labels_ == i][0:5]))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "30172d9a6c643631a2bbd2ccafbdc7b25d01eada6cb60dcb8ec3809d296c4202"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
